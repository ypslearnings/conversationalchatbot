{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx7CCJZKdcC2"
      },
      "source": [
        "# Building a Chatbot from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXhctcffDsE1",
        "outputId": "d8942bdf-b0c8-4125-c092-4d1fc50ebe37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsR2PuNPdcC5"
      },
      "source": [
        "##### In this project we will build a chatbot from scratch using the corenell University's Movie Dialogue corpus.\n",
        "##### We will be using a deep learning based architecture with the main components as a lstm based encoder and decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V7b5o0oxdcC7"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Dense, Input, Embedding\n",
        "from keras.layers import Dense, Input, Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_WFN5fXsdcDB"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import nltk\n",
        "import numpy\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv38ReVtdcDO"
      },
      "source": [
        "Download the glove model available at https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "Specification : Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 25d, 50d, 100d, & 200d vectors, 1.42 GB download): glove.twitter.27B.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXuwJNpGdcDQ"
      },
      "source": [
        "you can download it with 'wget' or can directly put the embedding zip file inside 'embedding_data' folder and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHx1FnytdcDU",
        "outputId": "88adffdb-91bb-450a-fbcc-6f5f2b9f385f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1449M  100 1449M    0     0  5152k      0  0:04:48  0:04:48 --:--:-- 5339k\n"
          ]
        }
      ],
      "source": [
        "! curl -o '/content/drive/MyDrive/Colab Notebooks/FinalProject/ChatBot/glove.twitter.27B.zip' http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WdsiHdOSniA",
        "outputId": "bed663a1-7a1b-4886-dacf-8d85a35b87b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab Notebooks/FinalProject/ChatBot/glove.twitter.27B.zip\n",
            "  inflating: /content/drive/MyDrive/Colab Notebooks/FinalProject/ChatBot/glovetwitter27B/glove.twitter.27B.25d.txt  \n",
            "  inflating: /content/drive/MyDrive/Colab Notebooks/FinalProject/ChatBot/glovetwitter27B/glove.twitter.27B.50d.txt  \n",
            "  inflating: /content/drive/MyDrive/Colab Notebooks/FinalProject/ChatBot/glovetwitter27B/glove.twitter.27B.100d.txt  \n",
            "  inflating: /content/drive/MyDrive/Colab Notebooks/FinalProject/ChatBot/glovetwitter27B/glove.twitter.27B.200d.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/drive/MyDrive/Colab Notebooks/FinalProject/ChatBot/glove.twitter.27B.zip' -d '/content/drive/MyDrive/Colab Notebooks/FinalProject/ChatBot/glovetwitter27B'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F_yG4mV2dcDZ"
      },
      "outputs": [],
      "source": [
        "RAND_STATE=np.random.seed(42)\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 10\n",
        "GLOVE_EMBEDDING_SIZE = 100\n",
        "HIDDEN_UNITS = 256\n",
        "MAX_INPUT_SEQ_LENGTH = 40\n",
        "MAX_TARGET_SEQ_LENGTH = 40\n",
        "MAX_VOCAB_SIZE = 10000\n",
        "DATA_SET_NAME = '/content/drive/MyDrive/Colab Notebooks/FinalProject/ChatBot/cornell'\n",
        "DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/FinalProject/ChatBot/cornell_movie_quotes_corpus/References/movie_lines_cleaned.txt'\n",
        "GLOVE_MODEL = \"/content/drive/MyDrive/Colab Notebooks/FinalProject/ChatBot/glovetwitter27B/glove.twitter.27B.100d.txt\"\n",
        "WHITELIST = 'abcdefghijklmnopqrstuvwxyz1234567890?.,'\n",
        "WEIGHT_FILE_PATH =  DATA_SET_NAME + '/word-glove-weights.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nsku9GyddcDe"
      },
      "outputs": [],
      "source": [
        "def in_white_list(_word):\n",
        "    # Define the set of allowed characters\n",
        "    white_list_chars = set('abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890')\n",
        "\n",
        "    # Check if every character in the word is in the whitelist\n",
        "    return all(char in white_list_chars for char in _word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKA3WnoNdcDk"
      },
      "source": [
        "Load the glove word embedding in to a dictionary where the **key** is a unique **word token** and the **value** is a **d** dimension vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ6Q6VpHdcDn"
      },
      "source": [
        "# Test-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_DtZYF8_dcDp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_glove_vector():\n",
        "    _word2embedding = {}\n",
        "    file = open(GLOVE_MODEL, mode='rt', encoding='utf8')\n",
        "    for line in file:\n",
        "        parts = line.strip().split()\n",
        "        # Check if the line has an expected number of parts (1 word + 100 dimensions)\n",
        "        if len(parts) == 101:\n",
        "            word = parts[0]\n",
        "            vector = np.asarray(parts[1:], dtype='float32')\n",
        "            _word2embedding[word] = vector\n",
        "        else:\n",
        "            print(f\"Skipped line: {line.strip()}\")\n",
        "    file.close()\n",
        "    return _word2embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdoRZsWEdcDs",
        "outputId": "6d05e8e8-aab3-46f9-8907-81e5049f84ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped line: -0.32053 -0.73053 -0.15227 0.75504 0.11011 0.14091 0.047278 -1.0087 0.13282 -0.10939 -0.010336 0.32189 -1.4589 -0.83385 -0.52429 0.55353 0.054966 0.02489 0.066947 0.39403 -0.2942 -1.2322 -0.2594 -0.72149 0.3671 0.24201 0.023268 0.14087 0.60309 0.37282 0.40474 0.16387 1.5523 -0.28782 -0.26105 -0.83564 -0.031021 0.26182 -0.093516 -0.36343 -0.10013 -0.113 1.3461 -0.7571 -0.51527 -0.0099121 -0.34748 0.2534 0.43839 0.30234 0.0080009 0.51505 0.25082 -0.53778 0.20495 0.27272 0.13311 0.98437 -0.24143 0.041526 0.21953 -0.20118 0.068255 1.2481 -0.28648 -0.058264 0.18604 0.45244 0.36555 0.35107 0.78051 -0.20271 0.99956 -0.4688 -0.49431 -0.14843 0.0022548 -0.10625 -0.21541 -0.24243 -0.68123 -0.17896 -0.86271 0.74024 0.73827 0.4905 -0.71627 -0.49518 0.050481 -0.21521 -1.21 0.38652 -0.22538 0.52208 0.62189 0.44918 -0.229 0.045921 0.73164 -0.23074\n",
            "Number of words in GloVe: 1193513\n"
          ]
        }
      ],
      "source": [
        "word2embedding = load_glove_vector()\n",
        "print(\"Number of words in GloVe:\", len(word2embedding))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu1WwP20dcDw"
      },
      "source": [
        "# Check-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VknKfgmGdcDz"
      },
      "outputs": [],
      "source": [
        "assert len(word2embedding.keys())==1193513\n",
        "for key in word2embedding.keys():\n",
        "    try:\n",
        "        assert len(word2embedding[key])==100\n",
        "    except AssertionError:\n",
        "        print (key,len(word2embedding[key]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCix18rAdcD7"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bkKBqppEdcD8"
      },
      "outputs": [],
      "source": [
        "target_counter = Counter()\n",
        "lines = open(DATA_PATH, 'rt', encoding='utf8').read().split('\\n')\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "prev_words = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWgKEMi2ZPnv",
        "outputId": "6fd85144-c383-4247-b624-dcb1ec9b3956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FsdjO_jdcD_"
      },
      "outputs": [],
      "source": [
        "for line in lines:\n",
        "    next_words = [w.lower() for w in nltk.word_tokenize(line)]\n",
        "    if len(next_words) > MAX_TARGET_SEQ_LENGTH:\n",
        "        next_words = next_words[0:MAX_TARGET_SEQ_LENGTH]\n",
        "    if len(prev_words) > 0:\n",
        "        input_texts.append(prev_words)\n",
        "        target_words = next_words[:]\n",
        "        target_words.insert(0, 'start')\n",
        "        target_words.append('end')\n",
        "        for w in target_words:\n",
        "            target_counter[w] += 1\n",
        "        target_texts.append(target_words)\n",
        "    prev_words = next_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcYFBgUIdcEF"
      },
      "source": [
        "Filter the conversations till max word length and convert the dialogues pairs into input text and target texts. Put **start** and **end** token to recognise the beginning and end of the sentence token.\n",
        "\n",
        "## Let's see some of the training examples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(target_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqZSDLTYeKf0",
        "outputId": "b64ba560-c600-4350-f152-35da51f0b0b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "304446"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiCxfQtBdcEG",
        "outputId": "52f5f3a5-a689-4773-fbbc-fd3085bbed06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['they', 'do', 'not', '!'], ['start', 'they', 'do', 'to', '!', 'end']]\n",
            "[['they', 'do', 'to', '!'], ['start', 'i', 'hope', 'so', '.', 'end']]\n",
            "[['i', 'hope', 'so', '.'], ['start', 'she', 'okay', '?', 'end']]\n",
            "[['she', 'okay', '?'], ['start', 'let', \"'s\", 'go', '.', 'end']]\n",
            "[['let', \"'s\", 'go', '.'], ['start', 'wow', 'end']]\n",
            "[['wow'], ['start', 'okay', '--', 'you', \"'re\", 'gon', 'na', 'need', 'to', 'learn', 'how', 'to', 'lie', '.', 'end']]\n",
            "[['okay', '--', 'you', \"'re\", 'gon', 'na', 'need', 'to', 'learn', 'how', 'to', 'lie', '.'], ['start', 'no', 'end']]\n",
            "[['no'], ['start', 'i', \"'m\", 'kidding', '.', 'you', 'know', 'how', 'sometimes', 'you', 'just', 'become', 'this', '``', 'persona', \"''\", '?', 'and', 'you', 'do', \"n't\", 'know', 'how', 'to', 'quit', '?', 'end']]\n",
            "[['i', \"'m\", 'kidding', '.', 'you', 'know', 'how', 'sometimes', 'you', 'just', 'become', 'this', '``', 'persona', \"''\", '?', 'and', 'you', 'do', \"n't\", 'know', 'how', 'to', 'quit', '?'], ['start', 'like', 'my', 'fear', 'of', 'wearing', 'pastels', '?', 'end']]\n",
            "[['like', 'my', 'fear', 'of', 'wearing', 'pastels', '?'], ['start', 'the', '``', 'real', 'you', \"''\", '.', 'end']]\n"
          ]
        }
      ],
      "source": [
        "for idx, (input_words, target_words) in enumerate(zip(input_texts, target_texts)):\n",
        "  if idx < 10:\n",
        "    print([input_words, target_words])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksKxizS6dcEL"
      },
      "source": [
        "### Create two dictionaries\n",
        "<ol>\n",
        "<li>target_word2id\n",
        "<li>target_id2word\n",
        "</ol>\n",
        "and save it as NumPy file format in the disk.\n",
        "<p>\n",
        "<strong>NOTE:</strong> The ids should start from 1 beacause <strong>0</strong> is reserved for <strong>'unknown'</strong> tokens.\n",
        "Make sure you consider only the <strong>most common</strong> tokens with <strong>MAX_VOCAB_SIZE</strong> defined above.\n",
        "\n",
        "Most common refers to tokens with higher frequency.\n",
        "</p>\n",
        "<strong>Help:</strong>\n",
        "<ol>\n",
        "<li>Use the target_counter which have the token counts.  \n",
        "<li>Use target_counter.most_common(MAX_VOCAB_SIZE) to filter common tokens\n",
        "    </ol>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc6oco8qdcEN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Initialize the dictionary with special tokens\n",
        "target_word2idx = {}\n",
        "\n",
        "# Start assigning indices from 1\n",
        "idx = 1\n",
        "\n",
        "# Sort the words in target_counter by frequency in descending order\n",
        "sorted_target_words = sorted(target_counter.most_common(MAX_VOCAB_SIZE), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for word, _ in sorted_target_words:\n",
        "    target_word2idx[word] = idx\n",
        "    idx += 1\n",
        "\n",
        "if 'unk' not in target_word2idx:\n",
        "    target_word2idx['unk'] = 0\n",
        "\n",
        "# Create target_idx2word dictionary\n",
        "target_idx2word = {idx: word for word, idx in target_word2idx.items()}\n",
        "\n",
        "# Create directory if it does not exist\n",
        "if not os.path.exists(DATA_SET_NAME):\n",
        "    os.makedirs(DATA_SET_NAME)\n",
        "\n",
        "np.save( DATA_SET_NAME + '/word-glove-target-word2idx.npy', target_word2idx)\n",
        "np.save( DATA_SET_NAME + '/word-glove-target-idx2word.npy', target_idx2word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PzuUg4zdcER"
      },
      "source": [
        "# Check-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7pikaJfdcEU"
      },
      "outputs": [],
      "source": [
        "assert len (target_word2idx.keys())==len (target_idx2word.keys())==MAX_VOCAB_SIZE+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mw-Ly2xdcEc"
      },
      "source": [
        "# Prepare the input data with embedding\n",
        "The input data is a list of lists\n",
        "<ol>\n",
        "<li> First list is a list of sentences\n",
        "<li> Each sentence is a list of words\n",
        " </ol>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBmG1ea4dcEc",
        "outputId": "a867f10b-55a9-46fc-bc04-cc7c9a439b98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num_decoder_tokens': 10001, 'encoder_max_seq_length': 40, 'decoder_max_seq_length': 42}\n"
          ]
        }
      ],
      "source": [
        "input_texts_word2em = []\n",
        "target_texts_word2em = []\n",
        "encoder_max_seq_length = 0\n",
        "decoder_max_seq_length = 0\n",
        "num_decoder_tokens = len(target_word2idx)\n",
        "EMBEDDING_DIM = 100  # Assuming each word is represented by a 100-dimensional vector\n",
        "\n",
        "for input_words, target_words in zip(input_texts, target_texts):\n",
        "    encoder_input_wids = []\n",
        "    encoder_target_wids = []\n",
        "    for w in input_words:\n",
        "        emb = word2embedding.get(w, word2embedding.get('unk', np.zeros(EMBEDDING_DIM)))\n",
        "        encoder_input_wids.append(emb)\n",
        "    for word in target_words:\n",
        "        emb = word2embedding.get(word, np.zeros(EMBEDDING_DIM))  # Get the embedding vector\n",
        "        encoder_target_wids.append(emb)\n",
        "\n",
        "    input_texts_word2em.append(encoder_input_wids)\n",
        "    target_texts_word2em.append(encoder_target_wids)\n",
        "    encoder_max_seq_length = max(len(encoder_input_wids), encoder_max_seq_length)\n",
        "    decoder_max_seq_length = max(len(target_words), decoder_max_seq_length)\n",
        "\n",
        "context = {\n",
        "    'num_decoder_tokens': num_decoder_tokens,\n",
        "    'encoder_max_seq_length': encoder_max_seq_length,\n",
        "    'decoder_max_seq_length': decoder_max_seq_length\n",
        "}\n",
        "\n",
        "print(context)\n",
        "np.save(DATA_SET_NAME + '/word-glove-context.npy', context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8IJeZVkdcEg"
      },
      "source": [
        "# Check-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXaPOQlddcEh"
      },
      "outputs": [],
      "source": [
        "for input_text,input_text_embed in zip (input_texts,range(len(input_texts_word2em))):\n",
        "    assert (len(input_text)==len(input_texts_word2em[input_text_embed]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXh-5WEUdcEn"
      },
      "source": [
        "# Generate Training data per batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvg8LBt-dcEo"
      },
      "source": [
        "generate_batch takes input embedding data (input_word2em_data) and target text data (target_texts) and returns trainable X and Y.\n",
        "X is a list of [X1,X2]\n",
        "where\n",
        "X1 is encoder_input_data_batch( which is created by putting the word embedding(glove vector) of the input tokens) padded in to a shape of (BATCH_SIZE, encoder_max_seq_length, GLOVE_EMBEDDING_SIZE)\n",
        "\n",
        "X2 is decoder_input_data_batch which is created by putting the word embedding(glove vector) of the target_words tokens and padding it to a shape of (BATCH_SIZE, encoder_max_seq_length, GLOVE_EMBEDDING_SIZE)\n",
        "\n",
        "Y is decoder_target_data_batch which is in shape of (BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens)\n",
        "which signifies for each target token text  in the batch we have an option of any token from the vocabularu to be the next predicted word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37R_9qpHdcEp"
      },
      "outputs": [],
      "source": [
        "def generate_batch(input_word2em_data, output_text_data):\n",
        "    num_batches = len(input_word2em_data) // BATCH_SIZE\n",
        "    while True:  # Loop forever so the generator never terminates\n",
        "        for batchIdx in range(0, num_batches):\n",
        "            start = batchIdx * BATCH_SIZE\n",
        "            end = (batchIdx + 1) * BATCH_SIZE\n",
        "            encoder_input_data_batch = np.zeros((BATCH_SIZE, encoder_max_seq_length, GLOVE_EMBEDDING_SIZE), dtype='float32')\n",
        "            decoder_input_data_batch = np.zeros((BATCH_SIZE, decoder_max_seq_length, GLOVE_EMBEDDING_SIZE), dtype='float32')\n",
        "            decoder_target_data_batch = np.zeros((BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens), dtype='float32')\n",
        "\n",
        "            for lineIdx, (input_text, output_text) in enumerate(zip(input_word2em_data[start:end], output_text_data[start:end])):\n",
        "              for wordIdx, word in enumerate(input_text):\n",
        "                  # Ensure word is a string\n",
        "                  if isinstance(word, str):\n",
        "                      encoder_input_data_batch[lineIdx, wordIdx, :] = word2embedding.get(word, np.zeros((GLOVE_EMBEDDING_SIZE,)))\n",
        "              for wordIdx, word in enumerate(output_text):\n",
        "                  # Ensure word is a string\n",
        "                  if isinstance(word, str):\n",
        "                      decoder_input_data_batch[lineIdx, wordIdx, :] = word2embedding.get(word, np.zeros((GLOVE_EMBEDDING_SIZE,)))\n",
        "                      # Use index for 'unk' if word is not in target_word2idx\n",
        "                      target_idx = target_word2idx.get(word, target_word2idx['unk'])\n",
        "                      if wordIdx > 0:\n",
        "                          decoder_target_data_batch[lineIdx, wordIdx - 1, target_idx] = 1\n",
        "            yield [encoder_input_data_batch, decoder_input_data_batch], decoder_target_data_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGjnjiyidcEt"
      },
      "source": [
        "# Check-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ezag0feRdcEu"
      },
      "outputs": [],
      "source": [
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(input_texts_word2em, target_texts, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = generate_batch(Xtrain, Ytrain)"
      ],
      "metadata": {
        "id": "HAeRtJxd8GCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j in train_gen:\n",
        "    assert i[0].shape==(BATCH_SIZE,context['encoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert i[1].shape==(BATCH_SIZE,context['decoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert j.shape==(BATCH_SIZE,context['decoder_max_seq_length'],context['num_decoder_tokens'])\n",
        "print ('Test Case 4 Passes!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OemLFgBAtlDk",
        "outputId": "c23ba375-72ec-414b-e1f5-6be4a16a16ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Case 4 Passes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jazC-goddcEx"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lab5ddRGdcEy",
        "outputId": "d714ab20-50ac-459b-f71a-899be270657d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 18,
          "metadata": {
            "image/png": {
              "height": 400,
              "width": 400
            },
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(filename='model.png',height=400,width=400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKnqwC4ndcE4"
      },
      "source": [
        "# The Model architecture is explained in the diagram above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8VfVTm4dcE6"
      },
      "source": [
        "# Test-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUJbRP9SdcE8"
      },
      "source": [
        "<ol>\n",
        "<li> Step 1: Use a LSTM encoder to get input words encoded in the form of (encoder outputs, encoder hidden state, encoder context) from input words\n",
        "<li> Step 2:  Use a LSTM decoder to get target words encoded in the form of (decoder outputs, decoder hidden state, decoder context) from target words. Use encoder hidden states and encoder context (represents input memory) as initial state .\n",
        "<li> Step 3: Use a dense layer to predict the next token out of the vocabulary given decoder output generated by Step 2.\n",
        "<li> Step 4: Use loss ='categorical_crossentropy' and optimizer='rmsprop'\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU974rtIdcE9"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Define parameters\n",
        "EMBEDDING_SIZE = 100\n",
        "ENCODER_UNITS = 256\n",
        "DECODER_UNITS = 256\n",
        "VOCAB_SIZE = 10002\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None, EMBEDDING_SIZE), name='encoder_inputs')\n",
        "encoder_lstm = LSTM(ENCODER_UNITS, return_state=True, name='encoder_lstm')\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None, EMBEDDING_SIZE), name='decoder_inputs')\n",
        "decoder_lstm = LSTM(DECODER_UNITS, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(VOCAB_SIZE, activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn `encoder_inputs` & `decoder_inputs` into `decoder_outputs`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnNAPfQFdcFG"
      },
      "source": [
        "# Check-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecKi6g5MdcFI"
      },
      "source": [
        "Check the model summary should look like this"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mN4E4Jy5Jjw",
        "outputId": "490ed4e1-53cb-4276-d4f1-139c63b275de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer  [(None, None, 100)]          0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer  [(None, None, 100)]          0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encoder_lstm (LSTM)         [(None, 256),                365568    ['encoder_inputs[0][0]']      \n",
            "                              (None, 256),                                                        \n",
            "                              (None, 256)]                                                        \n",
            "                                                                                                  \n",
            " decoder_lstm (LSTM)         [(None, None, 256),          365568    ['decoder_inputs[0][0]',      \n",
            "                              (None, 256),                           'encoder_lstm[0][1]',        \n",
            "                              (None, 256)]                           'encoder_lstm[0][2]']        \n",
            "                                                                                                  \n",
            " decoder_dense (Dense)       (None, None, 10002)          2570514   ['decoder_lstm[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3301650 (12.59 MB)\n",
            "Trainable params: 3301650 (12.59 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train\n"
      ],
      "metadata": {
        "id": "e1aWGy8_5sZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "BATCH_SIZE = 64  # Set the batch size\n",
        "EPOCHS = 30  # Set the number of epochs\n",
        "\n",
        "model.fit([input_texts_word2em, target_texts_word2em], Ytrain,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "id": "4_MYVQdW5zTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOTTSdcndcFS"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder model"
      ],
      "metadata": {
        "id": "cSvt7xPb-C4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder takes the same input as your seq2seq model's encoder\n",
        "encoder_inputs = model.input[0]  # encoder_inputs layer\n",
        "\n",
        "# Get the output of the encoder LSTM layer, which are the states\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # encoder_lstm layer\n",
        "\n",
        "# The states are used as the encoder model's output\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "metadata": {
        "id": "b9Y7HBCR-B7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder model"
      ],
      "metadata": {
        "id": "hLv7PDps-GkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder takes the same input as your seq2seq model's decoder\n",
        "decoder_inputs = model.input[1]  # decoder_inputs layer\n",
        "\n",
        "# Additional inputs for the states from the encoder\n",
        "decoder_state_input_h = Input(shape=(256,))  # Same as LSTM state size\n",
        "decoder_state_input_c = Input(shape=(256,))  # Same as LSTM state size\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Reuse the decoder LSTM layer from the trained model\n",
        "decoder_lstm = model.layers[3]  # decoder_lstm layer\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "\n",
        "# Reuse the decoder Dense layer from the trained model\n",
        "decoder_dense = model.layers[4]  # decoder_dense layer\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# The decoder model takes the decoder's inputs and the initial states and outputs the decoded sequence and the new states\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "metadata": {
        "id": "QCQVIMAm-Iin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_decoder_seq_length = 0\n",
        "for target_text in target_texts:\n",
        "    max_decoder_seq_length = max(max_decoder_seq_length, len(target_text))\n",
        "\n",
        "print(\"Maximum sequence length for the decoder:\", max_decoder_seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbkSAF_r-dKO",
        "outputId": "a3b43497-8d7b-428e-e6fb-74fb64454b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum sequence length for the decoder: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1 with only the start-of-sequence word\n",
        "    target_seq = np.zeros((1, 1, EMBEDDING_SIZE))\n",
        "    target_seq[0, 0] = word2embedding.get('<start>', np.zeros(EMBEDDING_SIZE))  # Handle missing embedding\n",
        "\n",
        "    # Loop and predict next words\n",
        "    stop_condition = False\n",
        "    decoded_sentence = []\n",
        "    while not stop_condition:\n",
        "      output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "      # Sample the next word\n",
        "      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "      sampled_word = target_idx2word.get(sampled_token_index, 'unk')  # Translate index to word\n",
        "\n",
        "      # Exit condition: either hit max length or find the stop character\n",
        "      if (sampled_word == '<end>' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "          stop_condition = True\n",
        "      else:\n",
        "          decoded_sentence.append(sampled_word)\n",
        "\n",
        "          # Update the target sequence (of length 1)\n",
        "          target_seq = np.zeros((1, 1, EMBEDDING_SIZE))\n",
        "          target_seq[0, 0] = word2embedding.get(sampled_word, np.zeros(EMBEDDING_SIZE))  # Handle missing embedding\n",
        "\n",
        "          # Update states\n",
        "          states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "ah4ZSgpH8bB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "ZgilWuH_-shR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Of all the words my father wrote - and there were many - I remember these the most: \\\"Nothing that results from human progress is achieved with unanimous consent. And those who are enlightened before the others are condemned to persue that light in spite of others. 1697 Of all the words my Father wrote and there were many, I remember these the most.  \\\"Nothing that results from human progress is achieved with unanimous consent...\\\"\"\n",
        "input_words = nltk.word_tokenize(input_text.lower())\n",
        "print(input_words)\n",
        "# Convert words to embeddings\n",
        "encoder_input_seq = np.zeros((1, encoder_max_seq_length, GLOVE_EMBEDDING_SIZE), dtype='float32')\n",
        "for i, word in enumerate(input_words):\n",
        "    if i < encoder_max_seq_length:\n",
        "        encoder_input_seq[0, i, :] = word2embedding.get(word, np.zeros((GLOVE_EMBEDDING_SIZE,)))\n",
        "print(\"Encoded input sentence\", encoder_input_seq)\n",
        "# Decode the sequence\n",
        "decoded_sentence = decode_sequence(encoder_input_seq)\n",
        "\n",
        "# Convert list of words back to a sentence\n",
        "decoded_sentence = ' '.join(decoded_sentence)\n",
        "print(\"Decoded sentence:\", decoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOjSJcC78c1z",
        "outputId": "e3c68015-03a8-49ae-a346-3bc9c5784895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['of', 'all', 'the', 'words', 'my', 'father', 'wrote', '-', 'and', 'there', 'were', 'many', '-', 'i', 'remember', 'these', 'the', 'most', ':', '``', 'nothing', 'that', 'results', 'from', 'human', 'progress', 'is', 'achieved', 'with', 'unanimous', 'consent', '.', 'and', 'those', 'who', 'are', 'enlightened', 'before', 'the', 'others', 'are', 'condemned', 'to', 'persue', 'that', 'light', 'in', 'spite', 'of', 'others', '.', '1697', 'of', 'all', 'the', 'words', 'my', 'father', 'wrote', 'and', 'there', 'were', 'many', ',', 'i', 'remember', 'these', 'the', 'most', '.', '``', 'nothing', 'that', 'results', 'from', 'human', 'progress', 'is', 'achieved', 'with', 'unanimous', 'consent', '...', \"''\"]\n",
            "Encoded input sentence [[[ 1.9323e-01 -2.6532e-01  2.3104e-01 ... -3.2829e-01  1.1387e+00\n",
            "    5.3168e-01]\n",
            "  [-4.2218e-01  1.6193e-01 -1.1836e-01 ... -3.2872e-01  6.6699e-01\n",
            "    1.6698e-01]\n",
            "  [ 9.5152e-02  3.7024e-01  5.4291e-01 ... -5.1083e-01  4.6877e-01\n",
            "    3.4882e-01]\n",
            "  ...\n",
            "  [ 2.3646e-01  2.3314e-01  9.8568e-03 ... -1.8920e-01  1.5352e-01\n",
            "    2.3014e-02]\n",
            "  [ 9.5152e-02  3.7024e-01  5.4291e-01 ... -5.1083e-01  4.6877e-01\n",
            "    3.4882e-01]\n",
            "  [-2.4833e-01  4.1618e-01  9.0800e-05 ... -1.3131e+00  2.2348e-01\n",
            "   -4.1199e-01]]]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Decoded sentence: los tank why b odds pegged sector dante otis pitch bloody hollis pegged chum chum experimental insists questioned breaks breaks pegged breaks pegged breaks pegged breaks n't pegged breaks financial pegged breaks bloody financial otis grendel swedish swedish scaring amigo scary clive grendel\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}